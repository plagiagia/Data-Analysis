{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing the News Headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geonamescache\n",
    "from collections import Counter\n",
    "import unidecode\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the text file and make a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = pd.read_csv('discovering-disease-outbreaks-base/data/headlines.txt',\n",
    "                        header=None, \n",
    "                        delimiter='\\n',\n",
    "                        names=['Headlines'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headlines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Rumors about Rotavirus spreading in Huntsville...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>Zika Outbreak in Puducherry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>Respiratory Syncytial Virus Vaccine is now Req...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>More contaminated cattle reported in Bedford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>Fort Hood Reports its First Zika Patient</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headlines\n",
       "153  Rumors about Rotavirus spreading in Huntsville...\n",
       "385                        Zika Outbreak in Puducherry\n",
       "266  Respiratory Syncytial Virus Vaccine is now Req...\n",
       "343       More contaminated cattle reported in Bedford\n",
       "402           Fort Hood Reports its First Zika Patient"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of headlines: 650\n",
      "Max lenght of headlines: 87\n",
      "Min lenght of headlines: 16\n",
      "Average lenght of headlines: 40.78\n"
     ]
    }
   ],
   "source": [
    "# Check some informations about headlines\n",
    "print(\"Number of headlines: {}\".format(headlines.shape[0]))\n",
    "print(\"Max lenght of headlines: {}\".format(max([len(each[0]) for each in headlines.values])))\n",
    "print(\"Min lenght of headlines: {}\".format(min([len(each[0]) for each in headlines.values])))\n",
    "print(\"Average lenght of headlines: {:.2f}\".format(np.mean([len(each[0]) for each in headlines.values])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Countries and Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init geonamecashe instance\n",
    "gc = geonamescache.GeonamesCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the name of all the cities into a list\n",
    "cities = [city['name'] for city in gc.get_cities().values()]\n",
    "# Extract all the country names into a list\n",
    "countries = [country['name'] for country in gc.get_countries().values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of cities: 24474\n",
      "Total number of countries: 252\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of cities: {}\".format(len(cities)))\n",
    "print(\"Total number of countries: {}\".format(len(countries)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('San Fernando', 8),\n",
       " ('Springfield', 8),\n",
       " ('San Pedro', 7),\n",
       " ('Richmond', 7),\n",
       " ('Mercedes', 6),\n",
       " ('La Paz', 6),\n",
       " ('Victoria', 6),\n",
       " ('Santa Rosa', 6),\n",
       " ('San Juan', 6),\n",
       " ('San Francisco', 6)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find duplicate\n",
    "city_counter = Counter(cities)\n",
    "city_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove accent marks\n",
    "country_accent_mapping = {\n",
    "    unidecode.unidecode(country): country for country in countries}\n",
    "\n",
    "city_accent_mapping = {\n",
    "    unidecode.unidecode(city): city for city in cities\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the dataframe from accent marks\n",
    "headlines_clean = pd.DataFrame(\n",
    "    {\n",
    "        \"Headlines\":[unidecode.unidecode(headline[0]) for headline in headlines.values]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned cities and countries into a list\n",
    "clean_cities = list(city_accent_mapping.keys())\n",
    "clean_countries = set(country_accent_mapping.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the city and country names\n",
    "clean_cities = sorted(clean_cities, key=lambda x: len(x), reverse=True)\n",
    "clean_countries = sorted(clean_countries, key=lambda x:len(x), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_regex = r'\\b|\\b'.join(clean_cities)\n",
    "country_regex = r'\\b|\\b'.join(clean_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_country_and_city(headline):\n",
    "    city = re.search(city_regex, headline)\n",
    "    country = re.search(country_regex, headline)\n",
    "    cities = None if not city else city.group(0)\n",
    "    countries = None if not country else country.group(0)\n",
    "    return dict(headline=headline, countries=countries, cities=cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines_extracted_cities_countries = [\n",
    "    find_country_and_city(headline[0]) for headline in headlines.values\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(headlines_extracted_cities_countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save files for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = \"headlines_with_city_country.json\"\n",
    "with open(save_file, 'w') as f:\n",
    "    f.write(json.dumps(headlines_extracted_cities_countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"city_accent_mapping.json\", 'w') as f:\n",
    "    f.write(json.dumps(city_accent_mapping))\n",
    "    \n",
    "with open(\"country_accent_mapping.json\", 'w') as f:\n",
    "    f.write(json.dumps(country_accent_mapping))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_country_and_city_v2(headline):\n",
    "    city_match = re.search(city_regex, headline)\n",
    "    country_match = re.search(country_regex, headline)\n",
    "    city = None if not city_match else city_match.group(0)\n",
    "    country = None if not country_match else country_match.group(0)\n",
    "\n",
    "    possible_city = sorted([each for each in gc.get_cities_by_name(city)], \n",
    "                                 key=lambda x:list(x.values())[0]['population'], \n",
    "                                 reverse=True)\n",
    "    \n",
    "    \n",
    "    if len(possible_city) > 0:\n",
    "        countrycode = list(possible_city[0].values())[0].get('countrycode')\n",
    "        lat = list(possible_city[0].values())[0].get('latitude')\n",
    "        lon = list(possible_city[0].values())[0].get('longitude')\n",
    "        id = list(possible_city[0].values())[0].get('geonameid')  \n",
    "        country=gc.get_countries().get(countrycode).get('name')\n",
    "    \n",
    "    else:\n",
    "        lat = None\n",
    "        lon = None\n",
    "        id = None\n",
    "        \n",
    "    return dict(headline=headline, country=country, city=city, id=str(id), latitude=lat, longitude=lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines_extracted_cities_countries_v2 = [\n",
    "    find_country_and_city_v2(headline[0]) for headline in headlines.values\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "headlines_v2 = pd.DataFrame(headlines_extracted_cities_countries_v2).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = \"headlines_with_city_country_lat_lon.json\"\n",
    "with open(save_file, 'w') as f:\n",
    "    f.write(json.dumps(headlines_extracted_cities_countries_v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Schools in Birmingham Closed Due to Measles Ou...</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>2655603</td>\n",
       "      <td>52.48142</td>\n",
       "      <td>-1.89983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>Spanish Flu Spreading through Madrid</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>3117735</td>\n",
       "      <td>40.41650</td>\n",
       "      <td>-3.70256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Zika case reported in Coral Gables</td>\n",
       "      <td>United States</td>\n",
       "      <td>Coral Gables</td>\n",
       "      <td>4151871</td>\n",
       "      <td>25.72149</td>\n",
       "      <td>-80.26838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Cancun hit by Outbreak of Party Fever!</td>\n",
       "      <td>None</td>\n",
       "      <td>Cancun</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>Zika Outbreak in Yurimaguas</td>\n",
       "      <td>Peru</td>\n",
       "      <td>Yurimaguas</td>\n",
       "      <td>3690654</td>\n",
       "      <td>-5.90181</td>\n",
       "      <td>-76.12234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              headline         country  \\\n",
       "231  Schools in Birmingham Closed Due to Measles Ou...  United Kingdom   \n",
       "484               Spanish Flu Spreading through Madrid           Spain   \n",
       "211                 Zika case reported in Coral Gables   United States   \n",
       "116             Cancun hit by Outbreak of Party Fever!            None   \n",
       "636                        Zika Outbreak in Yurimaguas            Peru   \n",
       "\n",
       "             city       id  latitude  longitude  \n",
       "231    Birmingham  2655603  52.48142   -1.89983  \n",
       "484        Madrid  3117735  40.41650   -3.70256  \n",
       "211  Coral Gables  4151871  25.72149  -80.26838  \n",
       "116        Cancun     None       NaN        NaN  \n",
       "636    Yurimaguas  3690654  -5.90181  -76.12234  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines_v2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
